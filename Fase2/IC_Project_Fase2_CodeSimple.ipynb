{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4739b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import pyswarms as ps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ed6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_street_data(path, street_types, im_size):\n",
    "    images, labels = [], []\n",
    "    streets = [(item, os.path.join(path, item, street)) \n",
    "               for item in street_types \n",
    "               for street in os.listdir(os.path.join(path, item))]\n",
    "    streets_df = pd.DataFrame(streets, columns=['street type', 'image'])\n",
    "    \n",
    "    for _, row in streets_df.iterrows():\n",
    "        img = load_img(row['image'], target_size=(im_size, im_size))\n",
    "        images.append(img_to_array(img))\n",
    "        labels.append(row['street type'])\n",
    "    \n",
    "    return np.array(images, dtype='float32') / 255.0, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b579fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstreet_types = ['clean', 'litter', 'recycle']\\npath = '../Dataset/'\\npath_test = '../Dataset_Test/'\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define o tamanho da imagem e os tipos de rua\n",
    "im_size = 350  # Exemplo de tamanho de imagem\n",
    "\n",
    "\n",
    "street_types = ['Apple', 'Banana', 'Cocos']\n",
    "path = '../DatasetFruits/'\n",
    "path_test = '../DatasetFruits_Test/'\n",
    "\n",
    "\"\"\"\n",
    "street_types = ['clean', 'litter', 'recycle']\n",
    "path = '../Dataset/'\n",
    "path_test = '../Dataset_Test/'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3403c7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streets in each category: Apple     429\n",
      "Banana    427\n",
      "Cocos     427\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Criando dados de treino, validação e teste\n",
    "train_images, train_labels = create_street_data(path, street_types, im_size)\n",
    "test_images, test_labels = create_street_data(path_test, street_types, im_size)\n",
    "\n",
    "# Contando as ocorrências de cada tipo de rua e imprimindo\n",
    "streets_count = pd.value_counts(train_labels)\n",
    "print(\"Streets in each category:\", streets_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800bd43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1026, 350, 350, 3)\n",
      "Validation shape: (257, 350, 350, 3)\n",
      "Test shape: (189, 350, 350, 3)\n"
     ]
    }
   ],
   "source": [
    "# Convertendo etiquetas para valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Embaralhando e dividindo os dados de treino e validação\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_images, train_labels_encoded, test_size=0.2, random_state=415)\n",
    "\n",
    "# Imprimindo as formas dos conjuntos de dados\n",
    "print(f\"Train shape: {train_x.shape}\")\n",
    "print(f\"Validation shape: {val_x.shape}\")\n",
    "print(f\"Test shape: {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c88d2f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 44s 1s/step - loss: 3.6098 - accuracy: 0.9152 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 38s 1s/step - loss: 1.7428e-09 - accuracy: 1.0000 - val_loss: 2.3192e-09 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 37s 1s/step - loss: 4.6475e-09 - accuracy: 1.0000 - val_loss: 4.6385e-09 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 38s 1s/step - loss: 9.5274e-09 - accuracy: 1.0000 - val_loss: 4.6385e-09 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 39s 1s/step - loss: 7.7846e-09 - accuracy: 1.0000 - val_loss: 4.6385e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad9487aa00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo o modelo da rede neural convolucional\n",
    "model = Sequential([\n",
    "    # Primeira camada convolucional\n",
    "    Conv2D(64, (3, 3), activation='relu', input_shape=(im_size, im_size, 3)), #32\n",
    "    MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Segunda camada convolucional\n",
    "    #Conv2D(64, (3, 3), activation='relu'),\n",
    "    #MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Terceira camada convolucional\n",
    "    #Conv2D(128, (3, 3), activation='relu'),\n",
    "    #MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Camada de achatamento para converter as características 3D em 1D\n",
    "    Flatten(),\n",
    "    \n",
    "    # Camada densa com regularização para reduzir o sobreajuste\n",
    "    #Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # Camada de saída com softmax para classificação multiclasse\n",
    "    Dense(len(street_types), activation='softmax')   \n",
    "])\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',  # Função de perda para classificação multiclasse\n",
    "              metrics=['accuracy'])  # Métrica de avaliação\n",
    "\n",
    "# Treinando o modelo com os dados de treino e validando com o conjunto de validação\n",
    "model.fit(train_x, \n",
    "          train_y, \n",
    "          epochs=5,  # Número de épocas de treinamento\n",
    "          #batch_size=64,  # Tamanho do lote, descomente e ajuste se necessário\n",
    "          validation_data=(val_x, val_y))  # Usando os dados de validação aqui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5974e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 181ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "6/6 [==============================] - 1s 189ms/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels_encoded, verbose=1);\n",
    "\n",
    "y_pred_test = model.predict(test_images);\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1);\n",
    "\n",
    "y_true = test_labels_encoded;\n",
    "y_true_binarized = label_binarize(test_labels_encoded, classes=np.unique(test_labels_encoded));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c392b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 100.00%\n",
      "\n",
      "Confusion Matrix:\n",
      "[[63  0  0]\n",
      " [ 0 63  0]\n",
      " [ 0  0 63]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Apple       1.00      1.00      1.00        63\n",
      "      Banana       1.00      1.00      1.00        63\n",
      "       Cocos       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       189\n",
      "   macro avg       1.00      1.00      1.00       189\n",
      "weighted avg       1.00      1.00      1.00       189\n",
      "\n",
      "\n",
      "\n",
      "AUC for class Apple: 1.00\n",
      "AUC for class Banana: 1.00\n",
      "AUC for class Cocos: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Avaliação do modelo nos dados de teste\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\" + \"\\n\");\n",
    "\n",
    "# Matriz de confusão\n",
    "confusion_mtx = confusion_matrix(y_true, y_pred_test_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mtx)\n",
    "\n",
    "# Relatório de classificação\n",
    "class_report = classification_report(y_true, y_pred_test_classes, target_names=label_encoder.classes_)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "print(\"\\n\")\n",
    "\n",
    "y_true_binarized = label_binarize(test_labels_encoded, classes=np.unique(test_labels_encoded));\n",
    "\n",
    "# Calculando o AUC para cada classe\n",
    "for i in range(y_true_binarized.shape[1]):  # Percorre cada classe\n",
    "    auc_score = roc_auc_score(y_true_binarized[:, i], y_pred_test[:, i])\n",
    "    print(f'AUC for class {label_encoder.classes_[i]}: {auc_score:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": false,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
