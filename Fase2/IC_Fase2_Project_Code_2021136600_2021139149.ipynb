{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4739b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  # Para pré-processamento de dados\n",
    "from sklearn.utils import shuffle  # Para embaralhar os dados\n",
    "from sklearn.model_selection import train_test_split  # Para dividir o conjunto de dados em treinamento e teste\n",
    "from sklearn.metrics import (  # Métricas de avaliação de modelo\n",
    "    confusion_matrix, accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    ")\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam  # Otimizador para a rede neural\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Pré-processamento de imagens\n",
    "\n",
    "import keras  # Biblioteca Keras para criação de modelos de redes neurais\n",
    "import tensorflow as tf  # TensorFlow para construção de redes neurais\n",
    "\n",
    "import matplotlib.pyplot as plt  # Para plotagem de gráficos\n",
    "import pandas as pd  # Manipulação de dados em formato tabular\n",
    "import numpy as np  # Biblioteca NumPy para manipulação de matrizes\n",
    "import cv2  # OpenCV para processamento de imagens\n",
    "import os  # Operações com sistema de arquivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ed6ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clean', 'litter', 'recycle']\n",
      "Tipos de ruas encontrados:  3\n"
     ]
    }
   ],
   "source": [
    "path = 'Dataset/'  # Definindo o caminho do diretório contendo o dataset\n",
    "im_size = 350  # Definindo o tamanho desejado para as imagens\n",
    "path_test = 'Dataset_Test/'  # Path to the test dataset\n",
    "\n",
    "street_types = os.listdir(path)  # Listando os tipos de ruas disponíveis no diretório\n",
    "street_types_test = os.listdir(path_test)\n",
    "\n",
    "print(street_types)  # Imprimindo os tipos de ruas encontrados\n",
    "print(\"Tipos de ruas encontrados: \", len(street_types))  # Imprimindo o número de tipos de ruas encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b579fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets = []  # Lista vazia para armazenar informações das ruas\n",
    "\n",
    "# Iterando sobre os diferentes tipos de ruas\n",
    "for item in street_types:\n",
    "    all_streets = os.listdir(path + '/' + item)  # Obtendo todos os nomes de arquivo na pasta\n",
    "    \n",
    "    # Adicionando os nomes de arquivo à lista 'streets'\n",
    "    for street in all_streets:\n",
    "        streets.append((item, str(path + '/' + item) + '/' + street))\n",
    "\n",
    "# Criando um DataFrame do pandas com as informações das ruas\n",
    "streets_df = pd.DataFrame(data=streets, columns=['street type', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "800bd43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of streets in the Dataset:  4805\n",
      "Ruas em cada categoria: \n",
      "recycle    1675\n",
      "clean      1625\n",
      "litter     1505\n",
      "Name: street type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o número total de ruas no conjunto de dados\n",
    "print(\"Total number of streets in the Dataset: \", len(streets_df))\n",
    "\n",
    "# Contando o número de ruas em cada categoria e imprimindo os resultados\n",
    "street_count = streets_df['street type'].value_counts()\n",
    "print(\"Ruas em cada categoria: \")\n",
    "print(street_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef704697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista vazia para armazenar informações das ruas para teste\n",
    "streets_test = []\n",
    "\n",
    "# Iterando sobre os mesmos tipos de ruas, agora no conjunto de testes\n",
    "for item in street_types:\n",
    "    all_streets_test = os.listdir(os.path.join(path_test, item))  # Obtendo todos os nomes de arquivo na pasta de teste\n",
    "    \n",
    "    # Adicionando os nomes de arquivo à lista 'streets_test'\n",
    "    for street in all_streets_test:\n",
    "        streets_test.append((item, os.path.join(path_test, item, street)))\n",
    "\n",
    "# Criando um DataFrame do pandas com as informações das ruas para teste\n",
    "streets_test_df = pd.DataFrame(data=streets_test, columns=['street type', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f42a6c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of streets in the Dataset_test:  600\n",
      "Ruas em cada categoria: \n",
      "clean      200\n",
      "litter     200\n",
      "recycle    200\n",
      "Name: street type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o número total de ruas no conjunto de dados\n",
    "print(\"Total number of streets in the Dataset_test: \", len(streets_test_df))\n",
    "\n",
    "# Contando o número de ruas em cada categoria e imprimindo os resultados\n",
    "street_test_count = streets_test_df['street type'].value_counts()\n",
    "print(\"Ruas em cada categoria: \")\n",
    "print(street_test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf5e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape das imagens: (4805, 350, 350, 3)\n",
      "Shape das etiquetas: (4805,)\n"
     ]
    }
   ],
   "source": [
    "images = []  # Lista para armazenar as imagens\n",
    "labels = []  # Lista para armazenar as etiquetas das ruas\n",
    "\n",
    "# Iterando sobre os diferentes tipos de ruas\n",
    "for label in street_types:\n",
    "    data_path = os.path.join(path, label)  # Obtendo o caminho para os dados de uma categoria\n",
    "    filenames = os.listdir(data_path)  # Obtendo os nomes dos arquivos de imagem na categoria\n",
    "\n",
    "    # Iterando sobre os arquivos de imagem na categoria\n",
    "    for filename in filenames:\n",
    "        img_path = os.path.join(data_path, filename)  # Obtendo o caminho completo da imagem\n",
    "        img = load_img(img_path, target_size=(im_size, im_size))  # Carregando a imagem e redimensionando\n",
    "        img_array = img_to_array(img)  # Convertendo a imagem para um array numpy\n",
    "        images.append(img_array)  # Adicionando a imagem à lista de imagens\n",
    "        labels.append(label)  # Adicionando a etiqueta da rua à lista de etiquetas\n",
    "\n",
    "# Convertendo a lista de imagens e etiquetas para arrays numpy\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalizando os valores de pixel\n",
    "images = images.astype('float32') / 255.0\n",
    "\n",
    "# Verificando a forma (shape) dos arrays\n",
    "print(\"Shape das imagens:\", images.shape)\n",
    "print(\"Shape das etiquetas:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af0bf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape das imagens (teste): (600, 350, 350, 3)\n",
      "Shape das etiquetas (teste): (600,)\n"
     ]
    }
   ],
   "source": [
    "# Processamento das imagens de teste\n",
    "images_test = []  # Lista para armazenar as imagens de teste\n",
    "labels_test = []  # Lista para armazenar as etiquetas das ruas de teste\n",
    "\n",
    "# Iterando sobre os diferentes tipos de ruas para teste\n",
    "for label in street_types:\n",
    "    data_path_test = os.path.join(path_test, label)  # Obtendo o caminho para os dados de uma categoria de teste\n",
    "    filenames_test = os.listdir(data_path_test)  # Obtendo os nomes dos arquivos de imagem na categoria de teste\n",
    "\n",
    "    # Iterando sobre os arquivos de imagem na categoria de teste\n",
    "    for filename in filenames_test:\n",
    "        img_path = os.path.join(data_path_test, filename)  # Obtendo o caminho completo da imagem de teste\n",
    "        img = load_img(img_path, target_size=(im_size, im_size))  # Carregando a imagem de teste e redimensionando\n",
    "        img_array = img_to_array(img)  # Convertendo a imagem de teste para um array numpy\n",
    "        images_test.append(img_array)  # Adicionando a imagem de teste à lista de imagens de teste\n",
    "        labels_test.append(label)  # Adicionando a etiqueta da rua de teste à lista de etiquetas de teste\n",
    "\n",
    "# Convertendo a lista de imagens e etiquetas para arrays numpy para teste\n",
    "images_test = np.array(images_test)\n",
    "labels_test = np.array(labels_test)\n",
    "\n",
    "# Normalizando os valores de pixel para teste\n",
    "images_test = images_test.astype('float32') / 255.0\n",
    "\n",
    "# Verificando a forma (shape) dos arrays para teste\n",
    "print(\"Shape das imagens (teste):\", images_test.shape)\n",
    "print(\"Shape das etiquetas (teste):\", labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2340848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (4564, 350, 350, 3)\n",
      "Validation shape: (241, 350, 350, 3)\n",
      "Train labels shape: (4564,)\n",
      "Validation labels shape: (241,)\n",
      "Test shape: (600, 350, 350, 3)\n",
      "Test labels shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "# Obtendo as etiquetas das ruas do DataFrame de treino e validação\n",
    "y_train = streets_df['street type'].values\n",
    "\n",
    "# Convertendo as etiquetas para valores numéricos usando LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Embaralhando as imagens de treino e suas etiquetas para garantir uma mistura aleatória\n",
    "train_images, train_labels = shuffle(images, y_train_encoded, random_state=1)\n",
    "\n",
    "# Dividindo os dados apenas em conjuntos de treinamento e validação (não mais teste aqui)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_images, train_labels, test_size=0.05, random_state=415)\n",
    "\n",
    "# Imprimindo as formas (shapes) dos conjuntos de dados de treino e validação\n",
    "print(\"Train shape:\", train_x.shape)\n",
    "print(\"Validation shape:\", val_x.shape)\n",
    "print(\"Train labels shape:\", train_y.shape)\n",
    "print(\"Validation labels shape:\", val_y.shape)\n",
    "\n",
    "# Agora, para o conjunto de teste\n",
    "# Primeiro, extrai as etiquetas do DataFrame de teste\n",
    "y_test = streets_test_df['street type'].values\n",
    "# Aqui, você transforma as etiquetas de teste usando o mesmo label encoder usado para o treinamento\n",
    "# Isto é importante para garantir que as etiquetas correspondam entre os conjuntos de treino e teste\n",
    "test_labels = label_encoder.transform(y_test)\n",
    "\n",
    "# Seu conjunto de teste já foi carregado e processado nas etapas anteriores, então aqui você só precisa verificar seus shapes\n",
    "print(\"Test shape:\", images_test.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5763c4d2",
   "metadata": {},
   "source": [
    "# Definindo o modelo da rede neural convolucional\n",
    "model = keras.Sequential([\n",
    "    # Primeira camada convolucional\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(im_size, im_size, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Segunda camada convolucional\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Terceira camada convolucional\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # Camada de achatamento para converter as características 3D em 1D\n",
    "    keras.layers.Flatten(),\n",
    "    \n",
    "    # Camada densa com regularização para reduzir o sobreajuste\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    # Camada de saída com softmax para classificação multiclasse\n",
    "    keras.layers.Dense(len(street_types), activation='softmax')   \n",
    "])\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',  # Função de perda para classificação multiclasse\n",
    "              metrics=['accuracy'])  # Métrica de avaliação\n",
    "\n",
    "# Treinando o modelo com os dados de treino e validando com o conjunto de validação\n",
    "model.fit(train_x, \n",
    "          train_y, \n",
    "          epochs=5,  # Número de épocas de treinamento\n",
    "          #batch_size=64,  # Tamanho do lote, descomente e ajuste se necessário\n",
    "          validation_data=(val_x, val_y))  # Usando os dados de validação aqui\n",
    "\n",
    "# Após o treinamento, você vai querer avaliar o modelo no conjunto de teste, que é um processo separado\n",
    "# Primeiro, você precisa obter as probabilidades de classe previstas pelo modelo no conjunto de teste\n",
    "y_probs_test = model.predict(images_test)\n",
    "\n",
    "# Obtendo as previsões finais (índices da classe com a maior probabilidade) para o conjunto de teste\n",
    "y_pred_test = np.argmax(y_probs_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c392b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão (Teste):\n",
      "[[163  29   8]\n",
      " [  2 198   0]\n",
      " [ 11   6 183]]\n",
      "Relatório de Classificação (Teste):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean       0.93      0.81      0.87       200\n",
      "      litter       0.85      0.99      0.91       200\n",
      "     recycle       0.96      0.92      0.94       200\n",
      "\n",
      "    accuracy                           0.91       600\n",
      "   macro avg       0.91      0.91      0.91       600\n",
      "weighted avg       0.91      0.91      0.91       600\n",
      "\n",
      "AUC para classe clean: 0.96539375\n",
      "AUC para classe litter: 0.98608125\n",
      "AUC para classe recycle: 0.991225\n"
     ]
    }
   ],
   "source": [
    "# Calculando a matriz de confusão para o conjunto de teste\n",
    "confusion_test = confusion_matrix(test_labels, y_pred_test)\n",
    "print(\"Matriz de Confusão (Teste):\")\n",
    "print(confusion_test)\n",
    "\n",
    "# Gerando um relatório de classificação para o conjunto de teste\n",
    "report_test = classification_report(test_labels, y_pred_test, target_names=label_encoder.classes_, zero_division=1)\n",
    "print(\"Relatório de Classificação (Teste):\")\n",
    "print(report_test)\n",
    "\n",
    "# Calculando a Área sob a Curva (AUC) para cada classe no conjunto de teste\n",
    "for i in range(len(label_encoder.classes_)):\n",
    "    auc = roc_auc_score(test_labels == i, y_probs_test[:, i])\n",
    "    print(f\"AUC para classe {label_encoder.classes_[i]}: {auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
