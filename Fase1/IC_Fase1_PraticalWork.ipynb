{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4739b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  # Para pré-processamento de dados\n",
    "from sklearn.utils import shuffle  # Para embaralhar os dados\n",
    "from sklearn.model_selection import train_test_split  # Para dividir o conjunto de dados em treinamento e teste\n",
    "from sklearn.metrics import (  # Métricas de avaliação de modelo\n",
    "    confusion_matrix, accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    ")\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam  # Otimizador para a rede neural\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Pré-processamento de imagens\n",
    "\n",
    "import keras  # Biblioteca Keras para criação de modelos de redes neurais\n",
    "import tensorflow as tf  # TensorFlow para construção de redes neurais\n",
    "\n",
    "import matplotlib.pyplot as plt  # Para plotagem de gráficos\n",
    "import pandas as pd  # Manipulação de dados em formato tabular\n",
    "import numpy as np  # Biblioteca NumPy para manipulação de matrizes\n",
    "import cv2  # OpenCV para processamento de imagens\n",
    "import os  # Operações com sistema de arquivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ed6ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clean', 'litter', 'recycle']\n",
      "Tipos de ruas encontrados:  3\n"
     ]
    }
   ],
   "source": [
    "path = 'Dataset/'  # Definindo o caminho do diretório contendo o dataset\n",
    "im_size = 350  # Definindo o tamanho desejado para as imagens\n",
    "\n",
    "street_types = os.listdir(path)  # Listando os tipos de ruas disponíveis no diretório\n",
    "print(street_types)  # Imprimindo os tipos de ruas encontrados\n",
    "print(\"Tipos de ruas encontrados: \", len(street_types))  # Imprimindo o número de tipos de ruas encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b579fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets = []  # Lista vazia para armazenar informações das ruas\n",
    "\n",
    "# Iterando sobre os diferentes tipos de ruas\n",
    "for item in street_types:\n",
    "    all_streets = os.listdir(path + '/' + item)  # Obtendo todos os nomes de arquivo na pasta\n",
    "    \n",
    "    # Adicionando os nomes de arquivo à lista 'streets'\n",
    "    for street in all_streets:\n",
    "        streets.append((item, str(path + '/' + item) + '/' + street))\n",
    "\n",
    "# Criando um DataFrame do pandas com as informações das ruas\n",
    "streets_df = pd.DataFrame(data=streets, columns=['street type', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f42a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of streets in the Dataset:  5405\n",
      "Ruas em cada categoria: \n",
      "street type\n",
      "recycle    1875\n",
      "clean      1825\n",
      "litter     1705\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o número total de ruas no conjunto de dados\n",
    "print(\"Total number of streets in the Dataset: \", len(streets_df))\n",
    "\n",
    "# Contando o número de ruas em cada categoria e imprimindo os resultados\n",
    "street_count = streets_df['street type'].value_counts()\n",
    "print(\"Ruas em cada categoria: \")\n",
    "print(street_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf5e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape das imagens: (5405, 350, 350, 3)\n",
      "Shape das etiquetas: (5405,)\n"
     ]
    }
   ],
   "source": [
    "images = []  # Lista para armazenar as imagens\n",
    "labels = []  # Lista para armazenar as etiquetas das ruas\n",
    "\n",
    "# Iterando sobre os diferentes tipos de ruas\n",
    "for label in street_types:\n",
    "    data_path = os.path.join(path, label)  # Obtendo o caminho para os dados de uma categoria\n",
    "    filenames = os.listdir(data_path)  # Obtendo os nomes dos arquivos de imagem na categoria\n",
    "\n",
    "    # Iterando sobre os arquivos de imagem na categoria\n",
    "    for filename in filenames:\n",
    "        img_path = os.path.join(data_path, filename)  # Obtendo o caminho completo da imagem\n",
    "        img = load_img(img_path, target_size=(im_size, im_size))  # Carregando a imagem e redimensionando\n",
    "        img_array = img_to_array(img)  # Convertendo a imagem para um array numpy\n",
    "        images.append(img_array)  # Adicionando a imagem à lista de imagens\n",
    "        labels.append(label)  # Adicionando a etiqueta da rua à lista de etiquetas\n",
    "\n",
    "# Convertendo a lista de imagens e etiquetas para arrays numpy\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalizando os valores de pixel\n",
    "images = images.astype('float32') / 255.0\n",
    "\n",
    "# Verificando a forma (shape) dos arrays\n",
    "print(\"Shape das imagens:\", images.shape)\n",
    "print(\"Shape das etiquetas:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2340848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5134, 350, 350, 3)\n",
      "(271, 350, 350, 3)\n",
      "(5134,)\n",
      "(271,)\n"
     ]
    }
   ],
   "source": [
    "# Obtendo as etiquetas das ruas do DataFrame\n",
    "y = streets_df['street type'].values\n",
    "\n",
    "# Convertendo as etiquetas para valores numéricos usando LabelEncoder\n",
    "y_labelenconder = LabelEncoder()\n",
    "y = y_labelenconder.fit_transform(y)\n",
    "\n",
    "# Embaralhando as imagens e suas etiquetas para garantir uma mistura aleatória\n",
    "images, y = shuffle(images, y, random_state=1)\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.05, random_state=415)\n",
    "\n",
    "# Imprimindo as formas (shapes) dos conjuntos de dados\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a847bf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "161/161 [==============================] - 183s 1s/step - loss: 251.4524 - accuracy: 0.4453 - val_loss: 1.4733 - val_accuracy: 0.4649\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 161s 1s/step - loss: 1.2158 - accuracy: 0.5251 - val_loss: 1.4244 - val_accuracy: 0.3542\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 167s 1s/step - loss: 1.0305 - accuracy: 0.5541 - val_loss: 0.9245 - val_accuracy: 0.4834\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 165s 1s/step - loss: 0.8341 - accuracy: 0.6048 - val_loss: 1.0162 - val_accuracy: 0.5683\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 166s 1s/step - loss: 0.8088 - accuracy: 0.6301 - val_loss: 0.7999 - val_accuracy: 0.6125\n",
      "9/9 [==============================] - 3s 202ms/step\n"
     ]
    }
   ],
   "source": [
    "# Definindo o modelo da rede neural\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(im_size, im_size, 3)),\n",
    "    keras.layers.Dense(1024, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    #keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    #keras.layers.Dense(32, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(3, activation=tf.nn.softmax)   \n",
    "])\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.009),\n",
    "             loss='sparse_categorical_crossentropy',  # Função de perda para classificação multiclasse\n",
    "             metrics=['accuracy'])  # Métrica de avaliação\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(train_x, \n",
    "          train_y, \n",
    "          epochs=5,  # Número de épocas de treinamento\n",
    "          #batch_size=64,  # Tamanho do lote\n",
    "          validation_data=(test_x, test_y))  # Dados de validação\n",
    "\n",
    "# Obtendo as probabilidades de classe previstas\n",
    "y_probs = model.predict(test_x)\n",
    "\n",
    "# Obtendo as previsões finais (índices da classe com a maior probabilidade)\n",
    "y_pred = np.argmax(y_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c392b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "[[47 48  3]\n",
      " [ 9 55 10]\n",
      " [ 3 32 64]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean       0.80      0.48      0.60        98\n",
      "      litter       0.41      0.74      0.53        74\n",
      "     recycle       0.83      0.65      0.73        99\n",
      "\n",
      "    accuracy                           0.61       271\n",
      "   macro avg       0.68      0.62      0.62       271\n",
      "weighted avg       0.70      0.61      0.63       271\n",
      "\n",
      "AUC para classe clean: 0.8589123510675946\n",
      "AUC para classe litter: 0.7231444642612156\n",
      "AUC para classe recycle: 0.872093023255814\n"
     ]
    }
   ],
   "source": [
    "# Calculando a matriz de confusão\n",
    "confusion = confusion_matrix(test_y, y_pred)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion)\n",
    "\n",
    "# Gerando um relatório de classificação\n",
    "report = classification_report(test_y, y_pred, target_names=street_types, zero_division=1)\n",
    "print(report)\n",
    "\n",
    "# Calculando a Área sob a Curva (AUC) para cada classe\n",
    "for i in range(len(street_types)):\n",
    "    auc = roc_auc_score(test_y == i, y_probs[:, i])\n",
    "    print(f\"AUC para classe {street_types[i]}: {auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
