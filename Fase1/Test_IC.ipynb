{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4739b3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  # Para pré-processamento de dados\n",
    "from sklearn.utils import shuffle  # Para embaralhar os dados\n",
    "from sklearn.model_selection import train_test_split  # Para dividir o conjunto de dados em treinamento e teste\n",
    "from sklearn.metrics import (  # Métricas de avaliação de modelo\n",
    "    confusion_matrix, accuracy_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    ")\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam  # Otimizador para a rede neural\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Pré-processamento de imagens\n",
    "\n",
    "import keras  # Biblioteca Keras para criação de modelos de redes neurais\n",
    "import tensorflow as tf  # TensorFlow para construção de redes neurais\n",
    "\n",
    "import matplotlib.pyplot as plt  # Para plotagem de gráficos\n",
    "import pandas as pd  # Manipulação de dados em formato tabular\n",
    "import numpy as np  # Biblioteca NumPy para manipulação de matrizes\n",
    "import cv2  # OpenCV para processamento de imagens\n",
    "import os  # Operações com sistema de arquivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41ed6ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clean', 'litter', 'recycle']\n",
      "Tipos de ruas encontrados:  3\n"
     ]
    }
   ],
   "source": [
    "path = 'Dataset2/'  # Definindo o caminho do diretório contendo o dataset\n",
    "im_size = 350  # Definindo o tamanho desejado para as imagens\n",
    "\n",
    "street_types = os.listdir(path)  # Listando os tipos de ruas disponíveis no diretório\n",
    "print(street_types)  # Imprimindo os tipos de ruas encontrados\n",
    "print(\"Tipos de ruas encontrados: \", len(street_types))  # Imprimindo o número de tipos de ruas encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4b579fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "streets = []  # Lista vazia para armazenar informações das ruas\n",
    "\n",
    "# Iterando sobre os diferentes tipos de ruas\n",
    "for item in street_types:\n",
    "    all_streets = os.listdir(path + '/' + item)  # Obtendo todos os nomes de arquivo na pasta\n",
    "    \n",
    "    # Adicionando os nomes de arquivo à lista 'streets'\n",
    "    for street in all_streets:\n",
    "        streets.append((item, str(path + '/' + item) + '/' + street))\n",
    "\n",
    "# Criando um DataFrame do pandas com as informações das ruas\n",
    "streets_df = pd.DataFrame(data=streets, columns=['street type', 'image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f42a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of streets in the Dataset:  5405\n",
      "Ruas em cada categoria: \n",
      "street type\n",
      "recycle    1875\n",
      "clean      1825\n",
      "litter     1705\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o número total de ruas no conjunto de dados\n",
    "print(\"Total number of streets in the Dataset: \", len(streets_df))\n",
    "\n",
    "# Contando o número de ruas em cada categoria e imprimindo os resultados\n",
    "street_count = streets_df['street type'].value_counts()\n",
    "print(\"Ruas em cada categoria: \")\n",
    "print(street_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bf5e7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5405, 350, 350, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = []  # Lista para armazenar as imagens\n",
    "labels = []  # Lista para armazenar as etiquetas das ruas\n",
    "\n",
    "# Iterando sobre os diferentes tipos de ruas\n",
    "for label in street_types:\n",
    "    data_path = os.path.join(path, label)  # Obtendo o caminho para os dados de uma categoria\n",
    "    filenames = os.listdir(data_path)  # Obtendo os nomes dos arquivos de imagem na categoria\n",
    "\n",
    "    # Iterando sobre os arquivos de imagem na categoria\n",
    "    for filename in filenames:\n",
    "        img_path = os.path.join(data_path, filename)  # Obtendo o caminho completo da imagem\n",
    "        img = load_img(img_path, target_size=(im_size, im_size))  # Carregando a imagem e redimensionando\n",
    "        img_array = img_to_array(img)  # Convertendo a imagem para um array numpy\n",
    "        images.append(img_array)  # Adicionando a imagem à lista de imagens\n",
    "        labels.append(label)  # Adicionando a etiqueta da rua à lista de etiquetas\n",
    "\n",
    "# Convertendo a lista de imagens para um array numpy e normalizando os valores de pixel\n",
    "images = np.array(images)\n",
    "images = images.astype('float32') / 255.0\n",
    "\n",
    "# Obtendo a forma (shape) do array de imagens\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2340848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5134, 350, 350, 3)\n",
      "(271, 350, 350, 3)\n",
      "(5134,)\n",
      "(271,)\n"
     ]
    }
   ],
   "source": [
    "# Obtendo as etiquetas das ruas do DataFrame\n",
    "y = streets_df['street type'].values\n",
    "\n",
    "# Convertendo as etiquetas para valores numéricos usando LabelEncoder\n",
    "y_labelenconder = LabelEncoder()\n",
    "y = y_labelenconder.fit_transform(y)\n",
    "\n",
    "# Embaralhando as imagens e suas etiquetas para garantir uma mistura aleatória\n",
    "images, y = shuffle(images, y, random_state=1)\n",
    "\n",
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.05, random_state=415)\n",
    "\n",
    "# Imprimindo as formas (shapes) dos conjuntos de dados\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a847bf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "81/81 [==============================] - 37s 413ms/step - loss: 1.1941 - accuracy: 0.3450 - val_loss: 1.0928 - val_accuracy: 0.3616\n",
      "Epoch 2/10\n",
      "81/81 [==============================] - 28s 342ms/step - loss: 1.1001 - accuracy: 0.3450 - val_loss: 1.1092 - val_accuracy: 0.3653\n",
      "Epoch 3/10\n",
      "81/81 [==============================] - 27s 333ms/step - loss: 1.1009 - accuracy: 0.3420 - val_loss: 1.0949 - val_accuracy: 0.3653\n",
      "Epoch 4/10\n",
      "81/81 [==============================] - 27s 329ms/step - loss: 1.1005 - accuracy: 0.3266 - val_loss: 1.0974 - val_accuracy: 0.3653\n",
      "Epoch 5/10\n",
      "81/81 [==============================] - 27s 328ms/step - loss: 1.0986 - accuracy: 0.3403 - val_loss: 1.0960 - val_accuracy: 0.3653\n",
      "Epoch 6/10\n",
      "81/81 [==============================] - 27s 332ms/step - loss: 1.0983 - accuracy: 0.3362 - val_loss: 1.0936 - val_accuracy: 0.3653\n",
      "Epoch 7/10\n",
      "81/81 [==============================] - 26s 324ms/step - loss: 1.0989 - accuracy: 0.3459 - val_loss: 1.0958 - val_accuracy: 0.3653\n",
      "Epoch 8/10\n",
      "81/81 [==============================] - 26s 321ms/step - loss: 1.0984 - accuracy: 0.3451 - val_loss: 1.0944 - val_accuracy: 0.3653\n",
      "Epoch 9/10\n",
      "81/81 [==============================] - 26s 318ms/step - loss: 1.0984 - accuracy: 0.3370 - val_loss: 1.0951 - val_accuracy: 0.3653\n",
      "Epoch 10/10\n",
      "81/81 [==============================] - 25s 315ms/step - loss: 1.0986 - accuracy: 0.3459 - val_loss: 1.0931 - val_accuracy: 0.3653\n",
      "9/9 [==============================] - 1s 57ms/step\n"
     ]
    }
   ],
   "source": [
    "# Definindo o modelo da rede neural\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(im_size, im_size, 3)),  # Camada de achatamento para transformar a imagem em vetor\n",
    "    keras.layers.Dense(256, activation=tf.nn.tanh),  # Camada densa com ativação tangente hiperbólica\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),   # Camada densa adicional com ativação ReLU\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu),    # Outra camada densa adicional com ativação ReLU\n",
    "    keras.layers.Dense(3, activation=tf.nn.softmax)   # Camada de saída com ativação softmax (3 classes)\n",
    "])\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "             loss='sparse_categorical_crossentropy',  # Função de perda para classificação multiclasse\n",
    "             metrics=['accuracy'])  # Métrica de avaliação\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(train_x, \n",
    "          train_y, \n",
    "          epochs=10,  # Número de épocas de treinamento\n",
    "          batch_size=64,  # Tamanho do lote\n",
    "          validation_data=(test_x, test_y))  # Dados de validação\n",
    "\n",
    "# Obtendo as probabilidades de classe previstas\n",
    "y_probs = model.predict(test_x)\n",
    "\n",
    "# Obtendo as previsões finais (índices da classe com a maior probabilidade)\n",
    "y_pred = np.argmax(y_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c392b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de Confusão:\n",
      "[[ 0  0 98]\n",
      " [ 0  0 74]\n",
      " [ 0  0 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean       1.00      0.00      0.00        98\n",
      "      litter       1.00      0.00      0.00        74\n",
      "     recycle       0.37      1.00      0.54        99\n",
      "\n",
      "    accuracy                           0.37       271\n",
      "   macro avg       0.79      0.33      0.18       271\n",
      "weighted avg       0.77      0.37      0.20       271\n",
      "\n",
      "AUC para classe clean: 0.4962545711926389\n",
      "AUC para classe litter: 0.5084716696391823\n",
      "AUC para classe recycle: 0.49647639182522907\n"
     ]
    }
   ],
   "source": [
    "# Calculando a matriz de confusão\n",
    "confusion = confusion_matrix(test_y, y_pred)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion)\n",
    "\n",
    "# Gerando um relatório de classificação\n",
    "report = classification_report(test_y, y_pred, target_names=street_types, zero_division=1)\n",
    "print(report)\n",
    "\n",
    "# Calculando a Área sob a Curva (AUC) para cada classe\n",
    "for i in range(len(street_types)):\n",
    "    auc = roc_auc_score(test_y == i, y_probs[:, i])\n",
    "    print(f\"AUC para classe {street_types[i]}: {auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
