{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb30917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações essenciais para o projeto\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# TensorFlow e Keras para construção e treinamento de modelos de rede neural\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Scikit-learn para pré-processamento de dados, divisão de conjunto de dados e métricas de avaliação\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Bibliotecas de Otimização por Enxame de Partículas\n",
    "from SwarmPackagePy import gwo\n",
    "import pyswarms as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57818837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos Dados\n",
    "def create_street_data(path, street_types, im_size):\n",
    "    images, labels = [], []\n",
    "    streets = [(item, os.path.join(path, item, street)) \n",
    "               for item in street_types \n",
    "               for street in os.listdir(os.path.join(path, item))]\n",
    "    streets_df = pd.DataFrame(streets, columns=['street type', 'image'])\n",
    "    \n",
    "    for _, row in streets_df.iterrows():\n",
    "        img = load_img(row['image'], target_size=(im_size, im_size))\n",
    "        images.append(img_to_array(img))\n",
    "        labels.append(row['street type'])\n",
    "    \n",
    "    return np.array(images, dtype='float32') / 255.0, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb589dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o tamanho da imagem\n",
    "im_size = 224\n",
    "\n",
    "# Define o tipo de imagem\n",
    "\"\"\"street_types = ['Apple', 'Banana', 'Cocos']\n",
    "path = '../DatasetFruits/'\n",
    "path_test = '../DatasetFruits_Test/'\"\"\"\n",
    "\n",
    "street_types = ['clean', 'litter', 'recycle']\n",
    "path = '../Dataset/'\n",
    "path_test = '../Dataset_Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa9f77c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streets in each category: recycle    1500\n",
      "clean      1460\n",
      "litter     1364\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Criar dados de treino, validação e teste\n",
    "train_images, train_labels = create_street_data(path, street_types, im_size)\n",
    "test_images, test_labels = create_street_data(path_test, street_types, im_size)\n",
    "\n",
    "# Contar as ocorrencias de cada tipo de rua e mostrar\n",
    "streets_count = pd.value_counts(train_labels)\n",
    "print(\"Streets in each category:\", streets_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32e0eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3675, 224, 224, 3)\n",
      "Validation shape: (649, 224, 224, 3)\n",
      "Test shape: (1081, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Converter etiquetas para valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Baralhar e dividir os dados de treino e validação\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_images, train_labels_encoded, test_size=0.15, random_state=415)\n",
    "\n",
    "# Imprimir as formas dos conjuntos de dados\n",
    "print(f\"Train shape: {train_x.shape}\")\n",
    "print(f\"Validation shape: {val_x.shape}\")\n",
    "print(f\"Test shape: {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed294b8f-6c83-410d-8630-4c649ff21868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_network(hyperparameters, train_x, train_y, val_x, val_y, street_types):\n",
    "    learning_rate, dropout_rate = hyperparameters  \n",
    "    im_size = train_x.shape[1]\n",
    "    \n",
    "    # Carregar o modelo VGG16 pré-treinado, sem as camadas superiores\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
    "\n",
    "    # Congelar as camadas do modelo base\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Construção do modelo com as novas camadas\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(dropout_rate)(x)  # Usar a variável desempacotada\n",
    "    x = Dense(len(street_types), activation='softmax')(x)  # Saída com base no número de tipos de rua\n",
    "\n",
    "    # Montar o modelo final\n",
    "    model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "    # Compilar o modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Treinar o modelo\n",
    "    model.fit(train_x, \n",
    "              train_y, \n",
    "              epochs=5, \n",
    "              validation_data=(val_x, val_y), \n",
    "              verbose=0)\n",
    "    \n",
    "    # Avaliar o modelo\n",
    "    validation_loss, validation_accuracy = model.evaluate(val_x, val_y, verbose=0)\n",
    "    return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72e71d37-006b-4083-860d-99a35857af61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fitness_function(hyperparameters):\n",
    "    loss = train_network(hyperparameters, train_x, train_y, val_x, val_y, street_types)\n",
    "    print(f\"Particle: {hyperparameters}, Loss: {loss}\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cbac26-9dab-4a20-96e3-53fa4012bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros do GWO\n",
    "n_agents = 5\n",
    "n_iterations = 5\n",
    "dimensions = 2\n",
    "lower_bound = [0.00001, 0.0]  # Limites inferiores para taxa de aprendizado e dropout\n",
    "upper_bound = [0.1, 0.5]     # Limites superiores para taxa de aprendizado e dropout\n",
    "\n",
    "# Inicializar e executar o otimizador GWO\n",
    "optimizer = gwo(n_agents, fitness_function, lower_bound, upper_bound, dimensions, n_iterations)\n",
    "\n",
    "# Desempacotar os melhores híper-parâmetros encontrados\n",
    "best_learning_rate, best_dropout_rate = optimizer.get_Gbest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f508aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Carregar o modelo VGG16 pré-treinado, sem as camadas superiores\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
    "\n",
    "# Congelar as camadas do modelo base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Construção do modelo final com as melhores taxas de aprendizado e dropout encontradas pelo GWO\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(best_dropout_rate)(x)  # Usar o melhor dropout_rate encontrado pelo GWO\n",
    "x = Dense(len(street_types), activation='softmax')(x)  # Saída com base no número de tipos de rua\n",
    "\n",
    "# Montar o modelo final\n",
    "final_model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Compilar o modelo final com o melhor learning_rate encontrado pelo GWO\n",
    "final_model.compile(optimizer=Adam(best_learning_rate),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Treinar o modelo final\n",
    "history = final_model.fit(train_x, \n",
    "                          train_y, \n",
    "                          epochs=5,\n",
    "                          validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1165c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Melhor taxa de aprendizado: {best_learning_rate}\")\n",
    "print(f\"Melhor taxa de dropout: {best_dropout_rate}\")\n",
    "\n",
    "# Avaliar o modelo final nos dados de teste\n",
    "test_loss, test_accuracy = final_model.evaluate(test_images, test_labels_encoded, verbose=1)\n",
    "print(f\"\\nAcurácia no teste: {test_accuracy*100:.2f}%\\n\")\n",
    "\n",
    "# Realizar previsões nos dados de teste\n",
    "y_pred_test = final_model.predict(test_images)\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "# Matriz de confusão\n",
    "confusion_mtx = confusion_matrix(test_labels_encoded, y_pred_test_classes)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_mtx)\n",
    "\n",
    "# Relatório de classificação\n",
    "class_report = classification_report(test_labels_encoded, y_pred_test_classes, target_names=label_encoder.classes_)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(class_report)\n",
    "\n",
    "# Binarizar as etiquetas para cálculo do AUC\n",
    "y_true_binarized = to_categorical(test_labels_encoded)\n",
    "\n",
    "# Calculando o AUC para cada classe\n",
    "for i in range(y_true_binarized.shape[1]):  # Percorrer cada classe\n",
    "    auc_score = roc_auc_score(y_true_binarized[:, i], y_pred_test[:, i])\n",
    "    print(f'AUC para a classe {label_encoder.classes_[i]}: {auc_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4cbb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o caminho e o nome do arquivo para salvar o modelo\n",
    "model_save_path = 'IC_Project_Fase3_GWO_SaveModel.h5'\n",
    "\n",
    "# Salvar o modelo\n",
    "model.save(model_save_path)\n",
    "print(f\"Modelo salvo com sucesso em: {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
