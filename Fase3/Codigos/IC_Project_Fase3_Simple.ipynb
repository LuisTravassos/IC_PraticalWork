{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb30917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas\n",
    "from scipy.stats import loguniform, uniform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from SwarmPackagePy import gwo\n",
    "import pyswarms as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57818837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamento das imagens\n",
    "def create_street_data(path, street_types, im_size):\n",
    "    images, labels = [], []\n",
    "    streets = [(item, os.path.join(path, item, street)) \n",
    "               for item in street_types \n",
    "               for street in os.listdir(os.path.join(path, item))]\n",
    "    streets_df = pd.DataFrame(streets, columns=['street type', 'image'])\n",
    "    \n",
    "    for _, row in streets_df.iterrows():\n",
    "        img = load_img(row['image'], target_size=(im_size, im_size))\n",
    "        images.append(img_to_array(img))\n",
    "        labels.append(row['street type'])\n",
    "    \n",
    "    return np.array(images, dtype='float32') / 255.0, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb589dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 224\n",
    "\n",
    "street_types = ['clean', 'litter', 'recycle']\n",
    "path = '../Dataset/'\n",
    "path_test = '../Dataset_Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa9f77c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streets in each category: recycle    1500\n",
      "clean      1460\n",
      "litter     1364\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = create_street_data(path, street_types, im_size)\n",
    "test_images, test_labels = create_street_data(path_test, street_types, im_size)\n",
    "\n",
    "streets_count = pd.value_counts(train_labels)\n",
    "print(\"Streets in each category:\", streets_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b32e0eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3675, 224, 224, 3)\n",
      "Validation shape: (649, 224, 224, 3)\n",
      "Test shape: (1081, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_images, train_labels_encoded, test_size=0.15, random_state=415)\n",
    "\n",
    "print(f\"Train shape: {train_x.shape}\")\n",
    "print(f\"Validation shape: {val_x.shape}\")\n",
    "print(f\"Test shape: {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33f508aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "115/115 [==============================] - 472s 4s/step - loss: 0.2593 - accuracy: 0.9018 - val_loss: 0.1827 - val_accuracy: 0.9414\n",
      "Epoch 2/5\n",
      "115/115 [==============================] - 523s 5s/step - loss: 0.0910 - accuracy: 0.9722 - val_loss: 0.1321 - val_accuracy: 0.9692\n",
      "Epoch 3/5\n",
      "115/115 [==============================] - 551s 5s/step - loss: 0.0455 - accuracy: 0.9905 - val_loss: 0.1194 - val_accuracy: 0.9738\n",
      "Epoch 4/5\n",
      "115/115 [==============================] - 556s 5s/step - loss: 0.0303 - accuracy: 0.9956 - val_loss: 0.1251 - val_accuracy: 0.9738\n",
      "Epoch 5/5\n",
      "115/115 [==============================] - 563s 5s/step - loss: 0.0233 - accuracy: 0.9962 - val_loss: 0.1213 - val_accuracy: 0.9769\n"
     ]
    }
   ],
   "source": [
    "# Definição, compilação e treinamento\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(im_size, im_size, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.18)(x)\n",
    "x = Dense(len(street_types), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "model.compile(optimizer=Adam(0.000495),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, \n",
    "                    train_y, \n",
    "                    epochs=5,\n",
    "                    validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e1165c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 142s 4s/step - loss: 0.1263 - accuracy: 0.9593\n",
      "\n",
      "Acurácia no teste: 95.93%\n",
      "\n",
      "34/34 [==============================] - 139s 4s/step\n",
      "Matriz de Confusão:\n",
      "[[331  26   8]\n",
      " [  4 336   1]\n",
      " [  2   3 370]]\n",
      "\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clean       0.98      0.91      0.94       365\n",
      "      litter       0.92      0.99      0.95       341\n",
      "     recycle       0.98      0.99      0.98       375\n",
      "\n",
      "    accuracy                           0.96      1081\n",
      "   macro avg       0.96      0.96      0.96      1081\n",
      "weighted avg       0.96      0.96      0.96      1081\n",
      "\n",
      "AUC para a classe clean: 0.99\n",
      "AUC para a classe litter: 1.00\n",
      "AUC para a classe recycle: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Avaliação e análise\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels_encoded, verbose=1)\n",
    "print(f\"\\nAcurácia no teste: {test_accuracy*100:.2f}%\\n\")\n",
    "\n",
    "y_pred_test = model.predict(test_images)\n",
    "y_pred_test_classes = np.argmax(y_pred_test, axis=1)\n",
    "\n",
    "confusion_mtx = confusion_matrix(test_labels_encoded, y_pred_test_classes)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_mtx)\n",
    "\n",
    "class_report = classification_report(test_labels_encoded, y_pred_test_classes, target_names=label_encoder.classes_)\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(class_report)\n",
    "\n",
    "y_true_binarized = to_categorical(test_labels_encoded)\n",
    "\n",
    "for i in range(y_true_binarized.shape[1]):\n",
    "    auc_score = roc_auc_score(y_true_binarized[:, i], y_pred_test[:, i])\n",
    "    print(f'AUC para a classe {label_encoder.classes_[i]}: {auc_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a7fdec3-2ad8-4670-944a-59b195290d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados exportados para o arquivo 'IC_Project_Fase3_Simple_Excel.xlsx'\n"
     ]
    }
   ],
   "source": [
    "# Armazenamento do Excel e Modelo\n",
    "shapes_data = {\n",
    "    'Conjunto': ['Treino', 'Validação', 'Teste'],\n",
    "    'Formato': [train_x.shape, val_x.shape, test_images.shape]\n",
    "}\n",
    "df_shapes = pd.DataFrame(shapes_data)\n",
    "\n",
    "df_confusion_mtx = pd.DataFrame(confusion_mtx, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "\n",
    "report_data = classification_report(test_labels_encoded, y_pred_test_classes, target_names=label_encoder.classes_, output_dict=True)\n",
    "df_class_report = pd.DataFrame(report_data).transpose()\n",
    "\n",
    "auc_scores = {label_encoder.classes_[i]: roc_auc_score(y_true_binarized[:, i], y_pred_test[:, i]) for i in range(y_true_binarized.shape[1])}\n",
    "df_auc_scores = pd.DataFrame(list(auc_scores.items()), columns=['Classe', 'AUC'])\n",
    "\n",
    "with pd.ExcelWriter('IC_Project_Fase3_Simple_Excel.xlsx') as writer:\n",
    "    df_shapes.to_excel(writer, sheet_name='Formas dos Conjuntos', index=False)\n",
    "    df_confusion_mtx.to_excel(writer, sheet_name='Matriz de Confusão')\n",
    "    df_class_report.to_excel(writer, sheet_name='Relatório de Classificação')\n",
    "    df_auc_scores.to_excel(writer, sheet_name='AUC por Classe', index=False)\n",
    "\n",
    "print(\"Resultados exportados para o arquivo 'IC_Project_Fase3_Simple_Excel.xlsx'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb4cbb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo com sucesso em: IC_Project_Fase3_Simple_SaveModel.h5\n"
     ]
    }
   ],
   "source": [
    "model_save_path = 'IC_Project_Fase3_Simple_SaveModel.h5'\n",
    "\n",
    "model.save(model_save_path)\n",
    "print(f\"Modelo salvo com sucesso em: {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
